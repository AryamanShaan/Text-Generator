{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import keras\n",
    "import sys\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a txt file\n",
    "from __future__ import unicode_literals\n",
    "text = open('./The_Foundation_Series.txt', 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing Number of Characters to train with\n",
    "text = text[:50000]\n",
    "n_text = len(text)\n",
    "n_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of unique characters \n",
    "chars = sorted(set(text))\n",
    "n_chars = len(chars)\n",
    "n_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Mapping from characters to integer values\n",
    "map_char_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  49900\n"
     ]
    }
   ],
   "source": [
    "seq_size = 100\n",
    "input_seq = []\n",
    "target_char = []\n",
    "for i in range(n_text-seq_size):\n",
    "    seq_in = text[i: i + seq_size]\n",
    "    seq_out = text[i + seq_size]\n",
    "    input_seq.append([map_char_int[char] for char in seq_in])\n",
    "    target_char.append(map_char_int[seq_out])\n",
    "n_patterns = len(input_seq)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shaan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(input_seq, (n_patterns, seq_size, 1))\n",
    "# normalize\n",
    "X = X / float(n_chars)\n",
    "\n",
    "\n",
    "# one hot encode the output variable\n",
    "data = target_char\n",
    "values = np.array(data)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Embedding(n_chars,256, input_length = len(input_seq[0])))\n",
    "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(onehot_encoded.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 77)                9933      \n",
      "=================================================================\n",
      "Total params: 76,493\n",
      "Trainable params: 76,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_seq2 = []\n",
    "# list1 = []\n",
    "# for i in input_seq:\n",
    "#     for j in i:\n",
    "#         list1.append(j)\n",
    "#         input_seq2.append(list1)\n",
    "#         list1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "49900/49900 [==============================] - 123s 2ms/step - loss: 3.2150\n",
      "\n",
      "Epoch 00001: loss improved from inf to 3.21496, saving model to weights-improvement-01-3.2150.hdf5\n",
      "Epoch 2/20\n",
      "49900/49900 [==============================] - 120s 2ms/step - loss: 3.0886\n",
      "\n",
      "Epoch 00002: loss improved from 3.21496 to 3.08863, saving model to weights-improvement-02-3.0886.hdf5\n",
      "Epoch 3/20\n",
      "49900/49900 [==============================] - 117s 2ms/step - loss: 2.9625\n",
      "\n",
      "Epoch 00003: loss improved from 3.08863 to 2.96247, saving model to weights-improvement-03-2.9625.hdf5\n",
      "Epoch 4/20\n",
      "49900/49900 [==============================] - 122s 2ms/step - loss: 2.9179\n",
      "\n",
      "Epoch 00004: loss improved from 2.96247 to 2.91793, saving model to weights-improvement-04-2.9179.hdf5\n",
      "Epoch 5/20\n",
      "49900/49900 [==============================] - 120s 2ms/step - loss: 2.8901\n",
      "\n",
      "Epoch 00005: loss improved from 2.91793 to 2.89009, saving model to weights-improvement-05-2.8901.hdf5\n",
      "Epoch 6/20\n",
      "49900/49900 [==============================] - 114s 2ms/step - loss: 2.8726\n",
      "\n",
      "Epoch 00006: loss improved from 2.89009 to 2.87261, saving model to weights-improvement-06-2.8726.hdf5\n",
      "Epoch 7/20\n",
      "49900/49900 [==============================] - 109s 2ms/step - loss: 2.8519\n",
      "\n",
      "Epoch 00007: loss improved from 2.87261 to 2.85189, saving model to weights-improvement-07-2.8519.hdf5\n",
      "Epoch 8/20\n",
      "49900/49900 [==============================] - 110s 2ms/step - loss: 2.8332\n",
      "\n",
      "Epoch 00008: loss improved from 2.85189 to 2.83323, saving model to weights-improvement-08-2.8332.hdf5\n",
      "Epoch 9/20\n",
      "49900/49900 [==============================] - 110s 2ms/step - loss: 2.8104\n",
      "\n",
      "Epoch 00009: loss improved from 2.83323 to 2.81044, saving model to weights-improvement-09-2.8104.hdf5\n",
      "Epoch 10/20\n",
      "49900/49900 [==============================] - 102s 2ms/step - loss: 2.7852\n",
      "\n",
      "Epoch 00010: loss improved from 2.81044 to 2.78516, saving model to weights-improvement-10-2.7852.hdf5\n",
      "Epoch 11/20\n",
      "49900/49900 [==============================] - 104s 2ms/step - loss: 2.7621\n",
      "\n",
      "Epoch 00011: loss improved from 2.78516 to 2.76208, saving model to weights-improvement-11-2.7621.hdf5\n",
      "Epoch 12/20\n",
      "49900/49900 [==============================] - 106s 2ms/step - loss: 2.7382\n",
      "\n",
      "Epoch 00012: loss improved from 2.76208 to 2.73820, saving model to weights-improvement-12-2.7382.hdf5\n",
      "Epoch 13/20\n",
      "49900/49900 [==============================] - 109s 2ms/step - loss: 2.7187\n",
      "\n",
      "Epoch 00013: loss improved from 2.73820 to 2.71869, saving model to weights-improvement-13-2.7187.hdf5\n",
      "Epoch 14/20\n",
      "49900/49900 [==============================] - 93s 2ms/step - loss: 2.6978\n",
      "\n",
      "Epoch 00014: loss improved from 2.71869 to 2.69781, saving model to weights-improvement-14-2.6978.hdf5\n",
      "Epoch 15/20\n",
      "49900/49900 [==============================] - 77s 2ms/step - loss: 2.6785\n",
      "\n",
      "Epoch 00015: loss improved from 2.69781 to 2.67849, saving model to weights-improvement-15-2.6785.hdf5\n",
      "Epoch 16/20\n",
      "49900/49900 [==============================] - 78s 2ms/step - loss: 2.6604\n",
      "\n",
      "Epoch 00016: loss improved from 2.67849 to 2.66040, saving model to weights-improvement-16-2.6604.hdf5\n",
      "Epoch 17/20\n",
      "49900/49900 [==============================] - 79s 2ms/step - loss: 2.6375\n",
      "\n",
      "Epoch 00017: loss improved from 2.66040 to 2.63748, saving model to weights-improvement-17-2.6375.hdf5\n",
      "Epoch 18/20\n",
      "49900/49900 [==============================] - 77s 2ms/step - loss: 2.6158\n",
      "\n",
      "Epoch 00018: loss improved from 2.63748 to 2.61576, saving model to weights-improvement-18-2.6158.hdf5\n",
      "Epoch 19/20\n",
      "49900/49900 [==============================] - 77s 2ms/step - loss: 2.5975\n",
      "\n",
      "Epoch 00019: loss improved from 2.61576 to 2.59753, saving model to weights-improvement-19-2.5975.hdf5\n",
      "Epoch 20/20\n",
      "49900/49900 [==============================] - 77s 2ms/step - loss: 2.5819\n",
      "\n",
      "Epoch 00020: loss improved from 2.59753 to 2.58187, saving model to weights-improvement-20-2.5819.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b74f7ba90>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, onehot_encoded, epochs=20, batch_size=128 ,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    " filename = \"weights-improvement-20-2.5819.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" e series, \n",
      "where the series, to qualify, had to consist of at least three connected novels. It was t \"\n",
      "oe tore to te tee sore to the soet  \n",
      "\n",
      "\n",
      "\n",
      "   The \n",
      "oonee toe tooe th the tore  ao  and to toe to toe te the sere  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   The woie toe tore to the  ao ao toe toee   \n",
      "\n",
      "\n",
      "   The woie tee  aod to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe to th the sooe  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   The woee the  aor to the toe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and to toe toe  ao the tooe  ao  and "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-d9f1cd809853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(input_seq)-1)\n",
    "pattern = input_seq[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(10000):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_chars)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
